{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db0a610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imported Necessery Library\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768fd301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.3\n",
      "1.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96429f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  sentiment\n",
       "0  Absolutely wonderful - silky and sexy and comf...          2\n",
       "1  Love this dress!  it's sooo pretty.  i happene...          2\n",
       "2  I had such high hopes for this dress and reall...          1\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...          2\n",
       "4  This shirt is very flattering to all due to th...          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "final = pd.read_csv(\"Dataset/E-Commerce.csv\")\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6715e03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X=list(final['Review Text'])\n",
    "y=list(final['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064e2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86960c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c88089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be7148d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deffine the confussion matrix\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc6e10",
   "metadata": {},
   "source": [
    "## XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e472c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlnet-base-cased/resolve/main/spiece.model from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\df73bc9f8d13bf2ea4dab95624895e45a550a0f0a825e41fc25440bf367ee3c8.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9\n",
      "loading file https://huggingface.co/xlnet-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlnet-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer_config.json from cache at None\n",
      "loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\46f47734f3dcaef7e236b9a3e887f27814e18836a8db7e6a49148000058a1a54.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53\n",
      "loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
      "Model config XLNetConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLNetLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"model_type\": \"xlnet\",\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"pad_token_id\": 5,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 250\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"untie_r\": true,\n",
      "  \"use_mems_eval\": true,\n",
      "  \"use_mems_train\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
      "Model config XLNetConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLNetLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"model_type\": \"xlnet\",\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"pad_token_id\": 5,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 250\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"untie_r\": true,\n",
      "  \"use_mems_eval\": true,\n",
      "  \"use_mems_train\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/xlnet-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\9461853998373b0b2f8ef8011a13b62a2c5f540b2c535ef3ea46ed8a062b16a9.3e214f11a50e9e03eb47535b58522fc3cc11ac67c120a9450f6276de151af987\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "\n",
    "tokenizer_x = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model_x = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57f7ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = tokenizer_x(X_train, padding=True, truncation=True, max_length=512)\n",
    "test_enc = tokenizer_x(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "996461ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let’s turn our labels and encodings into a Dataset object for Training and test purpose \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_d = Dataset(train_enc, y_train)\n",
    "test_d = Dataset(test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "554cde77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "##set the training arguments for traning \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_x',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=4,             \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=16,  \n",
    "    warmup_steps=100,                \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ee71498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 350\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 1:08:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.087400</td>\n",
       "      <td>1.090721</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.189600</td>\n",
       "      <td>1.102081</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.080600</td>\n",
       "      <td>1.080992</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.069000</td>\n",
       "      <td>1.072175</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.082500</td>\n",
       "      <td>1.135205</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.329545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.085600</td>\n",
       "      <td>1.049600</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.038800</td>\n",
       "      <td>1.034556</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.088300</td>\n",
       "      <td>1.058840</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.893332</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.018600</td>\n",
       "      <td>0.888303</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.067400</td>\n",
       "      <td>1.139195</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.465909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.980300</td>\n",
       "      <td>0.820622</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>0.904716</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.871796</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.511364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.953006</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.860746</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.602273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.913870</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-10\n",
      "Configuration saved in ./results_x\\checkpoint-10\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-10\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-20\n",
      "Configuration saved in ./results_x\\checkpoint-20\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-20\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-30\n",
      "Configuration saved in ./results_x\\checkpoint-30\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-30\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-40\n",
      "Configuration saved in ./results_x\\checkpoint-40\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-40\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-50\n",
      "Configuration saved in ./results_x\\checkpoint-50\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-60\n",
      "Configuration saved in ./results_x\\checkpoint-60\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-60\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-70\n",
      "Configuration saved in ./results_x\\checkpoint-70\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-70\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-80\n",
      "Configuration saved in ./results_x\\checkpoint-80\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-80\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-90\n",
      "Configuration saved in ./results_x\\checkpoint-90\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-90\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-100\n",
      "Configuration saved in ./results_x\\checkpoint-100\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-110\n",
      "Configuration saved in ./results_x\\checkpoint-110\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-110\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-120\n",
      "Configuration saved in ./results_x\\checkpoint-120\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-120\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-130\n",
      "Configuration saved in ./results_x\\checkpoint-130\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-130\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-140\n",
      "Configuration saved in ./results_x\\checkpoint-140\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-140\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-150\n",
      "Configuration saved in ./results_x\\checkpoint-150\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-150\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-160\n",
      "Configuration saved in ./results_x\\checkpoint-160\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-160\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_x\\checkpoint-170\n",
      "Configuration saved in ./results_x\\checkpoint-170\\config.json\n",
      "Model weights saved in ./results_x\\checkpoint-170\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results_x\\checkpoint-120 (score: 0.8206222057342529).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=176, training_loss=0.9434558437629179, metrics={'train_runtime': 4122.483, 'train_samples_per_second': 0.34, 'train_steps_per_second': 0.043, 'total_flos': 126194107788000.0, 'train_loss': 0.9434558437629179, 'epoch': 4.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "\n",
    "trainer_x = Trainer(\n",
    "    model=model_x,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_d,       \n",
    "    eval_dataset=test_d,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_x.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6c9e9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 06:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.109796404838562,\n",
       " 'eval_accuracy': 0.3522727272727273,\n",
       " 'eval_precision': 0.3522727272727273,\n",
       " 'eval_recall': 0.3522727272727273,\n",
       " 'eval_f1': 0.3522727272727273,\n",
       " 'eval_runtime': 53.3791,\n",
       " 'eval_samples_per_second': 1.649,\n",
       " 'eval_steps_per_second': 0.112,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_x.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d01f5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "# #predict\n",
    "Pred_x = trainer_x.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6db8ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_x.predict(test_dataset)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "956ae825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "output_x=trainer_x.predict(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33ee2c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 35,  0],\n",
       "       [ 0,  0, 24]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=confusion_matrix(y_test,output_x)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b321842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Model/xlnet_model\n",
      "Configuration saved in ./Model/xlnet_model\\config.json\n",
      "Model weights saved in ./Model/xlnet_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save the DistilBert model\n",
    "trainer_x.save_model(\"./Model/xlnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24823a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557e0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e940b19d",
   "metadata": {},
   "source": [
    "### DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "261cc0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "#called the pretrained model (distilbert) for tokenization\n",
    "# from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizerFast,DistilBertForSequenceClassification,Trainer,TrainingArguments\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0c9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example \n",
    "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks annoyingly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e4788ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(sample_txt, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae7292f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: When was I last outside? I am stuck at home for 2 weeks annoyingly\n",
      "   Tokens: ['when', 'was', 'i', 'last', 'outside', '?', 'i', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', 'annoying', '##ly']\n",
      "Token IDs: [2043, 2001, 1045, 2197, 2648, 1029, 1045, 2572, 5881, 2012, 2188, 2005, 1016, 3134, 15703, 2135]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35d2eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tokenizer for training and test dataset (DistilBertTokenizerFast)\n",
    "\n",
    "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8e3f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let’s turn our labels and encodings into a Dataset object for Training and test purpose \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea80841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x1a50522b0d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb799888",
   "metadata": {},
   "outputs": [],
   "source": [
    "##set the training arguments for traning \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=3,             \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=16,  \n",
    "    warmup_steps=100,                \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31fe8dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 350\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 27:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.074600</td>\n",
       "      <td>1.086075</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.109800</td>\n",
       "      <td>1.085278</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.083100</td>\n",
       "      <td>1.080906</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.109900</td>\n",
       "      <td>1.076791</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.076200</td>\n",
       "      <td>1.074121</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.488636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.045700</td>\n",
       "      <td>1.042554</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.052500</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.909600</td>\n",
       "      <td>0.865011</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.932900</td>\n",
       "      <td>1.028448</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.909500</td>\n",
       "      <td>0.906280</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.556818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>0.826464</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.776237</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-10\n",
      "Configuration saved in ./results\\checkpoint-10\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-20\n",
      "Configuration saved in ./results\\checkpoint-20\\config.json\n",
      "Model weights saved in ./results\\checkpoint-20\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-30\n",
      "Configuration saved in ./results\\checkpoint-30\\config.json\n",
      "Model weights saved in ./results\\checkpoint-30\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-40\n",
      "Configuration saved in ./results\\checkpoint-40\\config.json\n",
      "Model weights saved in ./results\\checkpoint-40\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-50\n",
      "Configuration saved in ./results\\checkpoint-50\\config.json\n",
      "Model weights saved in ./results\\checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-60\n",
      "Configuration saved in ./results\\checkpoint-60\\config.json\n",
      "Model weights saved in ./results\\checkpoint-60\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-70\n",
      "Configuration saved in ./results\\checkpoint-70\\config.json\n",
      "Model weights saved in ./results\\checkpoint-70\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-80\n",
      "Configuration saved in ./results\\checkpoint-80\\config.json\n",
      "Model weights saved in ./results\\checkpoint-80\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-90\n",
      "Configuration saved in ./results\\checkpoint-90\\config.json\n",
      "Model weights saved in ./results\\checkpoint-90\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-100\n",
      "Configuration saved in ./results\\checkpoint-100\\config.json\n",
      "Model weights saved in ./results\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-110\n",
      "Configuration saved in ./results\\checkpoint-110\\config.json\n",
      "Model weights saved in ./results\\checkpoint-110\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-120\n",
      "Configuration saved in ./results\\checkpoint-120\\config.json\n",
      "Model weights saved in ./results\\checkpoint-120\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results\\checkpoint-130\n",
      "Configuration saved in ./results\\checkpoint-130\\config.json\n",
      "Model weights saved in ./results\\checkpoint-130\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-130 (score: 0.7762371301651001).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=132, training_loss=0.9354518715179327, metrics={'train_runtime': 1651.1017, 'train_samples_per_second': 0.636, 'train_steps_per_second': 0.08, 'total_flos': 38848309800300.0, 'train_loss': 0.9354518715179327, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "\n",
    "trainer_db = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,       \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_db.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83a94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 29:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7762371301651001,\n",
       " 'eval_accuracy': 0.6590909090909091,\n",
       " 'eval_precision': 0.6590909090909091,\n",
       " 'eval_recall': 0.6590909090909091,\n",
       " 'eval_f1': 0.6590909090909091,\n",
       " 'eval_runtime': 18.7084,\n",
       " 'eval_samples_per_second': 4.704,\n",
       " 'eval_steps_per_second': 0.321,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_db.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b998d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "# #predict\n",
    "Pred = trainer_db.predict(test_dataset)\n",
    "\n",
    "#pred, _, _ = trainer_db.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e144f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92078507,  0.80241716, -1.7717776 ],\n",
       "       [ 0.68479824,  1.0178638 , -1.8449914 ],\n",
       "       [ 0.52653664,  0.9653432 , -1.7092462 ],\n",
       "       [ 0.44136798,  0.87729305, -1.5850458 ],\n",
       "       [-1.5448184 , -0.0819838 ,  1.2862345 ],\n",
       "       [-1.3953059 , -0.21782114,  1.3653089 ],\n",
       "       [-0.596812  ,  0.51643634, -0.16759175],\n",
       "       [ 0.41798395,  0.728462  , -1.4674158 ],\n",
       "       [ 0.9537357 ,  0.7360021 , -1.9359077 ],\n",
       "       [ 0.7145629 ,  0.86994165, -1.8050945 ],\n",
       "       [ 1.3134803 ,  0.5125864 , -1.8324342 ],\n",
       "       [-0.94383097,  0.550618  ,  0.12206863],\n",
       "       [ 0.9015233 ,  0.8154589 , -1.827915  ],\n",
       "       [ 1.182108  ,  0.63631487, -1.8833137 ],\n",
       "       [ 0.8483616 ,  0.54114324, -1.5356498 ],\n",
       "       [ 0.660493  ,  0.528335  , -1.3744648 ],\n",
       "       [-1.489425  , -0.56670237,  1.8562918 ],\n",
       "       [ 0.69607425,  0.9580624 , -1.8039017 ],\n",
       "       [ 1.2227893 ,  0.52679586, -1.8078969 ],\n",
       "       [-1.4898564 , -0.6129006 ,  1.8789382 ],\n",
       "       [ 0.24912927,  0.70297253, -1.240468  ],\n",
       "       [ 0.83328706,  0.9697964 , -1.914372  ],\n",
       "       [ 0.7077142 ,  0.7771131 , -1.7284229 ],\n",
       "       [ 0.65972686,  0.9899363 , -1.7253671 ],\n",
       "       [-1.4951514 , -0.26175123,  1.6001778 ],\n",
       "       [ 1.1312597 ,  0.73437726, -1.9198679 ],\n",
       "       [ 0.4509493 ,  0.7094525 , -1.3785887 ],\n",
       "       [-0.6419229 ,  0.69112897, -0.22378153],\n",
       "       [ 0.8353839 ,  0.65690625, -1.7477423 ],\n",
       "       [ 1.164028  ,  0.6717027 , -1.9561279 ],\n",
       "       [ 0.39824605,  0.45713544, -1.0090257 ],\n",
       "       [-1.5071585 , -0.28215173,  1.5892055 ],\n",
       "       [ 0.2438823 ,  1.0898613 , -1.595737  ],\n",
       "       [-1.3031986 , -0.23615086,  1.4435582 ],\n",
       "       [ 0.96029234,  0.62989056, -1.7930322 ],\n",
       "       [-1.2313079 ,  0.12022945,  0.6955132 ],\n",
       "       [ 0.46185273,  0.78048354, -1.4355097 ],\n",
       "       [-1.5592632 , -0.4627452 ,  1.8243382 ],\n",
       "       [ 0.96785235,  0.5483751 , -1.6009842 ],\n",
       "       [ 0.795178  ,  0.7450781 , -1.6683868 ],\n",
       "       [ 0.61333203,  0.77987945, -1.5908364 ],\n",
       "       [ 1.05748   ,  0.7048186 , -1.8664893 ],\n",
       "       [ 1.000931  ,  0.70938385, -1.8700913 ],\n",
       "       [ 1.3674612 ,  0.45522237, -1.8042352 ],\n",
       "       [-1.555544  , -0.5940779 ,  1.885684  ],\n",
       "       [ 1.1553369 ,  0.685984  , -1.8905146 ],\n",
       "       [ 1.1060196 ,  0.6471251 , -1.8835366 ],\n",
       "       [-0.03076461,  0.49656016, -0.8483428 ],\n",
       "       [-1.5070301 , -0.29125726,  1.6420449 ],\n",
       "       [-1.3487287 , -0.36841553,  1.5288574 ],\n",
       "       [-1.484416  , -0.4129668 ,  1.7580026 ],\n",
       "       [ 0.88289064,  0.9529686 , -1.8904523 ],\n",
       "       [ 1.0318439 ,  0.7304951 , -1.8572893 ],\n",
       "       [ 0.6701882 ,  0.71481395, -1.5447259 ],\n",
       "       [-1.4545135 , -0.23572838,  1.586704  ],\n",
       "       [ 1.0271183 ,  0.6540334 , -1.7792081 ],\n",
       "       [ 0.01088925,  0.5931021 , -0.93926775],\n",
       "       [ 1.0170887 ,  0.8234527 , -1.9239372 ],\n",
       "       [-1.201745  ,  0.11573797,  0.78331256],\n",
       "       [-1.452531  , -0.5703907 ,  1.815178  ],\n",
       "       [ 1.0639341 ,  0.71898615, -1.9664245 ],\n",
       "       [ 0.5128261 ,  0.87681293, -1.4997306 ],\n",
       "       [ 1.3346444 ,  0.43102956, -1.7049438 ],\n",
       "       [ 0.23866412,  0.69168615, -1.0507429 ],\n",
       "       [ 1.1326251 ,  0.4413284 , -1.729327  ],\n",
       "       [ 1.1405517 ,  0.6801729 , -1.8914446 ],\n",
       "       [-1.5924048 , -0.31844148,  1.6988598 ],\n",
       "       [ 1.20274   ,  0.6407999 , -1.9116193 ],\n",
       "       [-1.5411146 , -0.50980276,  1.7492044 ],\n",
       "       [ 0.03425355,  0.6921981 , -0.91421676],\n",
       "       [-1.5736547 , -0.3102913 ,  1.6574423 ],\n",
       "       [ 0.97879696,  0.7139071 , -1.9665195 ],\n",
       "       [-1.1580219 , -0.17227706,  1.3365335 ],\n",
       "       [ 1.0355331 ,  0.64537895, -1.8966472 ],\n",
       "       [ 0.7633873 ,  0.93803126, -1.8966038 ],\n",
       "       [ 0.1969943 ,  0.78465784, -1.2278969 ],\n",
       "       [-0.13554746,  1.0293236 , -1.1964974 ],\n",
       "       [-1.5532979 , -0.04716436,  1.3326128 ],\n",
       "       [ 1.2908177 ,  0.5326023 , -1.8765718 ],\n",
       "       [-0.8938128 ,  0.17468935,  0.4992513 ],\n",
       "       [-1.5324637 , -0.3337718 ,  1.6259341 ],\n",
       "       [ 0.04896307,  1.0286485 , -1.211605  ],\n",
       "       [ 1.1079077 ,  0.7177277 , -1.9717509 ],\n",
       "       [ 0.8195152 ,  0.5487964 , -1.5218661 ],\n",
       "       [-1.4938892 , -0.4311571 ,  1.8061118 ],\n",
       "       [-1.3851471 , -0.2542686 ,  1.3555648 ],\n",
       "       [-1.5286056 , -0.26410517,  1.6250863 ],\n",
       "       [ 0.80075306,  0.9669574 , -1.8620749 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8812d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_db.predict(test_dataset)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b7618ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "output=trainer_db.predict(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32137694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0,\n",
       "       1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0,\n",
       "       2, 0, 0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 1, 0, 2, 2, 2, 1, 1, 2, 1, 2, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4080e81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 35,  0],\n",
       "       [ 0,  0, 24]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=confusion_matrix(y_test,output)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05f70c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Classification report\n",
    "# metrics.classification_report(y_test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9897d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "lev = {0:'Negative', 1:'Neutral', 2:'Positive'}\n",
    "plt.figure(figsize=(10,4))\n",
    "final.sentiment.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fa8d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(output, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44305733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>Pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love maeve and was so excited for this top w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I ordered this in the orange color from online...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, this top just did not do anything for me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fabric is beautiful, even the lining is lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice top. armholes are a bit oversized but as ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  actual_label  Pred_label\n",
       "0  I love maeve and was so excited for this top w...             0           0\n",
       "1  I ordered this in the orange color from online...             1           1\n",
       "2  Well, this top just did not do anything for me...             1           1\n",
       "3  The fabric is beautiful, even the lining is lo...             1           1\n",
       "4  Nice top. armholes are a bit oversized but as ...             2           2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for test data predictions\n",
    "\n",
    "dict1 = {\"text\":X_test, \"actual_label\": y_test, \"Pred_label\":output}\n",
    "df_pred = pd.DataFrame(dict1)\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f1c2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the prediciton\n",
    "df_pred.to_csv(\"Dataset/Prediction/test_pred_DistilBert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70855748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8985b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "\n",
    "n_class = 3\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_test, output, pos_label=i)\n",
    "    \n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass ROC',dpi=300);    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c58d9",
   "metadata": {},
   "source": [
    "### Inference from new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a8f1684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a cute top that can transition easily ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I absolutely love this bib tee! it's probably ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very soft and comfortable. the shirt has an un...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice top. armholes are a bit oversized but as ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is an adorable top that i find to be extr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating\n",
       "0  This is a cute top that can transition easily ...       4\n",
       "1  I absolutely love this bib tee! it's probably ...       5\n",
       "2  Very soft and comfortable. the shirt has an un...       5\n",
       "3  Nice top. armholes are a bit oversized but as ...       4\n",
       "4  This is an adorable top that i find to be extr...       5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.read_csv(\"Dataset/Rawdata.csv\")\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b776e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a37fb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Encode 1 star and 2 star as Negative rated 0.\n",
    "##Encode 3 star as neutral rated 1.\n",
    "##Encode 4 star and 5 star as positive rated 2.\n",
    "\n",
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd71d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the cindition to Rating Columns and created a new sentiment Column\n",
    "\n",
    "new['sentiment'] = new.Rating.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c135de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text    4\n",
      "Rating         0\n",
      "sentiment      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking the null values\n",
    "print(new.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d77e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d840494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a cute top that can transition easily ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I absolutely love this bib tee! it's probably ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very soft and comfortable. the shirt has an un...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice top. armholes are a bit oversized but as ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is an adorable top that i find to be extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  sentiment\n",
       "0  This is a cute top that can transition easily ...          2\n",
       "1  I absolutely love this bib tee! it's probably ...          2\n",
       "2  Very soft and comfortable. the shirt has an un...          2\n",
       "3  Nice top. armholes are a bit oversized but as ...          2\n",
       "4  This is an adorable top that i find to be extr...          2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = new.drop([\"Rating\"],axis=1)\n",
    "new_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f9664",
   "metadata": {},
   "source": [
    "### Single row inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f629c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset with level\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #print(item)\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])            \n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07fc0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "test_1 = list(new[\"Review Text\"][:1])\n",
    "\n",
    "#tokenized\n",
    "test_1_tokenized = tokenizer(test_1, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset_new_ = Dataset(test_1_tokenized)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred_, _, _ = trainer_db.predict(test_dataset_new_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ef3ca9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is a cute top that can transition easily from summer to fall. it fits well, nice print and it's comfortable. i tried this on in the store, but did not purchase it because the color washed me out. this is not the best color for a blonde. would look much better on a brunette. if this was in a different color i most likely would have purchased it.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1257bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lev = {0:'Negative', 1:'Neutral', 2:'Positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "875869e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d24c7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This is a cute top that can transition easily from summer to fall. it fits well, nice print and it's comfortable. i tried this on in the store, but did not purchase it because the color washed me out. this is not the best color for a blonde. would look much better on a brunette. if this was in a different color i most likely would have purchased it.\"]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(test_1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5b268",
   "metadata": {},
   "source": [
    "### dateset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c8aac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the test data\n",
    "\n",
    "test_all = list(new[\"Review Text\"])\n",
    "X_test_tokenized = tokenizer(test_all, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94a355f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d767163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "test_dataset_new = Dataset(X_test_tokenized )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc0b2a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "new_raw_pred, _, _ = trainer_db.predict(test_dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5af071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess raw predictions\n",
    "y_pred_ = np.argmax(new_raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c4dcd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1,\n",
       "       2, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a753bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a cute top that can transition easily ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I absolutely love this bib tee! it's probably ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very soft and comfortable. the shirt has an un...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice top. armholes are a bit oversized but as ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is an adorable top that i find to be extr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  sentiment\n",
       "0  This is a cute top that can transition easily ...          2\n",
       "1  I absolutely love this bib tee! it's probably ...          2\n",
       "2  Very soft and comfortable. the shirt has an un...          2\n",
       "3  Nice top. armholes are a bit oversized but as ...          2\n",
       "4  This is an adorable top that i find to be extr...          2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for test data predictions\n",
    "\n",
    "dict2 = {\"Review Text\":new[\"Review Text\"], \"sentiment\":y_pred_ }\n",
    "df_pred_new = pd.DataFrame(dict2)\n",
    "df_pred_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "626029f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new data inferences\n",
    "df_pred_new.to_csv(\"Dataset/new_test_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbe12c",
   "metadata": {},
   "source": [
    "### Save the model for future predection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b382606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Model/DistilBert_model\n",
      "Configuration saved in ./Model/DistilBert_model\\config.json\n",
      "Model weights saved in ./Model/DistilBert_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save the DistilBert model\n",
    "trainer_db.save_model(\"./Model/DistilBert_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1f36",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc0bc459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertModel,Trainer,TrainingArguments,BertForSequenceClassification\n",
    "#from transformers import BertTokenizerFast,BertForSequenceClassification,\n",
    "\n",
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89fc20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tokenizer for training and test dataset (BertTokenizer)\n",
    "\n",
    "train_encodings_bert = tokenizer_bert(X_train, padding=True, truncation=True, max_length=512)\n",
    "test_encodings_bert = tokenizer_bert(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "504ea11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let’s turn our labels and encodings into a Dataset object for Training and test purpose \n",
    "\n",
    "train = Dataset(train_encodings_bert, y_train)\n",
    "test = Dataset(test_encodings_bert, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b841089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "##set the training arguments for traning \n",
    "\n",
    "training_args_bert = TrainingArguments(\n",
    "    output_dir='./bertresults',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=4,             \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=16,  \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b4452aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 350\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 58:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.243500</td>\n",
       "      <td>1.199307</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.122600</td>\n",
       "      <td>1.161380</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.147000</td>\n",
       "      <td>1.097784</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.101200</td>\n",
       "      <td>1.086125</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.104800</td>\n",
       "      <td>1.096639</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.087300</td>\n",
       "      <td>1.101776</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.109300</td>\n",
       "      <td>1.074029</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.056200</td>\n",
       "      <td>1.067474</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.038800</td>\n",
       "      <td>1.079759</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.443182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.014200</td>\n",
       "      <td>1.060744</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>1.063309</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>1.086455</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.009900</td>\n",
       "      <td>1.170733</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>0.352273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>1.076026</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>1.098703</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>1.180862</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>1.168590</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-10\n",
      "Configuration saved in ./bertresults\\checkpoint-10\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-10\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-20\n",
      "Configuration saved in ./bertresults\\checkpoint-20\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-20\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-30\n",
      "Configuration saved in ./bertresults\\checkpoint-30\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-30\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-40\n",
      "Configuration saved in ./bertresults\\checkpoint-40\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-40\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-50\n",
      "Configuration saved in ./bertresults\\checkpoint-50\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-60\n",
      "Configuration saved in ./bertresults\\checkpoint-60\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-60\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-70\n",
      "Configuration saved in ./bertresults\\checkpoint-70\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-70\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-80\n",
      "Configuration saved in ./bertresults\\checkpoint-80\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-80\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-90\n",
      "Configuration saved in ./bertresults\\checkpoint-90\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-90\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-100\n",
      "Configuration saved in ./bertresults\\checkpoint-100\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-110\n",
      "Configuration saved in ./bertresults\\checkpoint-110\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-110\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-120\n",
      "Configuration saved in ./bertresults\\checkpoint-120\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-120\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-130\n",
      "Configuration saved in ./bertresults\\checkpoint-130\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-130\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-140\n",
      "Configuration saved in ./bertresults\\checkpoint-140\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-140\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-150\n",
      "Configuration saved in ./bertresults\\checkpoint-150\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-150\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-160\n",
      "Configuration saved in ./bertresults\\checkpoint-160\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-160\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./bertresults\\checkpoint-170\n",
      "Configuration saved in ./bertresults\\checkpoint-170\\config.json\n",
      "Model weights saved in ./bertresults\\checkpoint-170\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./bertresults\\checkpoint-100 (score: 1.0607444047927856).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=176, training_loss=1.0136404823173175, metrics={'train_runtime': 3534.0932, 'train_samples_per_second': 0.396, 'train_steps_per_second': 0.05, 'total_flos': 102881457478800.0, 'train_loss': 1.0136404823173175, 'epoch': 4.0})"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "\n",
    "trainer_bert = Trainer(\n",
    "    model=model_bert,                         \n",
    "    args=training_args_bert,                 \n",
    "    train_dataset=train,       \n",
    "    eval_dataset=test,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7b936dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 02:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0607444047927856,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_precision': 0.5,\n",
       " 'eval_recall': 0.5,\n",
       " 'eval_f1': 0.5,\n",
       " 'eval_runtime': 47.6897,\n",
       " 'eval_samples_per_second': 1.845,\n",
       " 'eval_steps_per_second': 0.126,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_bert.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1a2729d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.87298551e-01, -3.64647567e-01, -8.96236449e-02],\n",
       "       [-2.11581767e-01,  1.95936561e-01, -4.23953503e-01],\n",
       "       [-2.80604541e-01,  1.96618244e-01, -4.18403119e-01],\n",
       "       [-7.96730146e-02,  6.28905892e-02, -3.45726848e-01],\n",
       "       [-7.58217722e-02, -9.97054726e-02, -2.91446865e-01],\n",
       "       [-1.94114760e-01,  7.76649565e-02, -5.17515182e-01],\n",
       "       [-4.19882089e-02,  2.86607761e-02, -2.96896875e-01],\n",
       "       [ 1.37966007e-01, -4.32309270e-01, -1.20062768e-01],\n",
       "       [-2.31400117e-01,  1.67472914e-01, -4.50053811e-01],\n",
       "       [-8.18147138e-02, -4.34415676e-02, -2.83878505e-01],\n",
       "       [-1.30667433e-01,  1.38912976e-01, -4.02140915e-01],\n",
       "       [-3.83297056e-01,  2.92086422e-01, -4.94296908e-01],\n",
       "       [-1.76658422e-01,  1.06103018e-01, -3.13393474e-01],\n",
       "       [ 9.08846408e-03, -2.94724666e-02, -4.03559238e-01],\n",
       "       [ 3.18353921e-01, -4.45301116e-01, -1.14234000e-01],\n",
       "       [ 1.56180076e-02, -2.60536492e-01, -1.26423627e-01],\n",
       "       [ 1.54924504e-02, -1.98468491e-01, -1.57126188e-01],\n",
       "       [ 1.35607943e-01, -2.86578029e-01, -2.29766324e-01],\n",
       "       [ 4.90546763e-01, -6.49874091e-01, -7.74479210e-02],\n",
       "       [ 4.33537483e-01, -5.67218244e-01,  1.08666062e-01],\n",
       "       [-1.87357426e-01,  1.50398463e-02, -4.42024052e-01],\n",
       "       [-1.21243328e-01,  6.78083822e-02, -3.76913488e-01],\n",
       "       [ 9.31216627e-02, -2.41309613e-01, -2.21326262e-01],\n",
       "       [-2.40252659e-01,  1.79803297e-01, -4.14294153e-01],\n",
       "       [-8.72862190e-02, -3.65069732e-02, -2.41361856e-01],\n",
       "       [-2.42456391e-01,  1.20461501e-01, -3.43928307e-01],\n",
       "       [ 6.04125708e-02, -1.10248066e-02, -2.24729747e-01],\n",
       "       [-2.77584434e-01,  1.81403250e-01, -3.44838411e-01],\n",
       "       [ 1.95716619e-01, -3.51019382e-01, -9.47036892e-02],\n",
       "       [ 3.89492154e-01, -4.60186213e-01, -2.17776895e-02],\n",
       "       [ 4.89928722e-01, -6.79020286e-01,  5.24263084e-02],\n",
       "       [-6.33586347e-02, -8.54692310e-02, -2.52945036e-01],\n",
       "       [-3.74510974e-01,  2.17492089e-01, -4.33345258e-01],\n",
       "       [ 2.77524769e-01, -4.65202212e-01, -3.76602113e-02],\n",
       "       [ 8.58237669e-02, -1.45492673e-01, -3.49219084e-01],\n",
       "       [ 2.93837860e-03, -5.19224554e-02, -2.52417743e-01],\n",
       "       [ 1.50803849e-01, -4.02863950e-01, -9.74484682e-02],\n",
       "       [ 1.76392183e-01, -2.72241086e-01, -1.07329726e-01],\n",
       "       [ 1.52405113e-01, -1.62433624e-01, -2.16085464e-01],\n",
       "       [ 6.33852556e-02, -5.91868609e-02, -2.58266091e-01],\n",
       "       [ 4.98687848e-03, -1.64771691e-01, -3.13044786e-01],\n",
       "       [ 5.42794243e-02, -1.95959002e-01, -9.76651013e-02],\n",
       "       [ 3.48085374e-01, -5.29444456e-01, -9.34424251e-02],\n",
       "       [ 2.48167515e-01, -4.58794475e-01, -1.29711032e-01],\n",
       "       [ 4.13452834e-03, -1.62732810e-01, -1.95204616e-01],\n",
       "       [ 1.19894750e-01, -1.49247766e-01, -2.51825124e-01],\n",
       "       [-7.05694556e-02, -5.70271909e-03, -2.44822711e-01],\n",
       "       [ 1.05513893e-02, -1.42602488e-01, -2.51135081e-01],\n",
       "       [ 3.38622332e-01, -5.54725885e-01, -4.67717946e-02],\n",
       "       [ 2.31366187e-01, -5.23623407e-01,  1.65314376e-02],\n",
       "       [-3.19506638e-02, -1.37100816e-01, -2.31475204e-01],\n",
       "       [-2.76690751e-01,  2.19888121e-01, -4.38697278e-01],\n",
       "       [-3.90625224e-02, -1.01996966e-01, -2.40831628e-01],\n",
       "       [ 1.04702115e-02, -8.60145912e-02, -1.22325018e-01],\n",
       "       [-1.78810209e-01,  3.76489125e-02, -3.40485305e-01],\n",
       "       [ 2.34297231e-01, -4.35677439e-01, -9.64351594e-02],\n",
       "       [ 4.96623516e-02, -5.29626012e-02, -2.53471971e-01],\n",
       "       [ 3.13955322e-02, -1.45887226e-01, -3.01880807e-01],\n",
       "       [-1.29939854e-01,  3.95140834e-02, -2.83267647e-01],\n",
       "       [ 6.12767413e-02, -2.06473559e-01, -1.01668924e-01],\n",
       "       [ 2.17390060e-02, -6.75431490e-02, -2.52674282e-01],\n",
       "       [-1.41743392e-01,  9.42631885e-02, -3.37520212e-01],\n",
       "       [ 6.20675683e-01, -7.37370968e-01,  8.11949372e-02],\n",
       "       [-1.41343117e-01, -3.63521278e-04, -3.91312599e-01],\n",
       "       [-1.00025021e-01,  3.10763009e-02, -3.92695785e-01],\n",
       "       [ 3.41606140e-02, -2.08421096e-01, -2.70355463e-01],\n",
       "       [-1.81276843e-01,  2.70946100e-02, -3.41668963e-01],\n",
       "       [-2.37779886e-01,  1.57145128e-01, -4.75799471e-01],\n",
       "       [-1.77842140e-01, -6.20979294e-02, -2.10134208e-01],\n",
       "       [-9.42281932e-02,  1.23196542e-02, -2.84662664e-01],\n",
       "       [-4.46705908e-01,  3.13885123e-01, -4.63768244e-01],\n",
       "       [-2.46742144e-01,  6.47681430e-02, -4.27685678e-01],\n",
       "       [ 1.16901368e-01, -2.58307040e-01,  4.11127210e-02],\n",
       "       [-3.38469744e-02, -1.76968202e-02, -3.51059437e-01],\n",
       "       [-2.50248283e-01,  8.53923559e-02, -2.75120139e-01],\n",
       "       [-1.69745505e-01,  1.09398574e-01, -2.97320187e-01],\n",
       "       [-9.02035907e-02,  5.78960851e-02, -2.94859320e-01],\n",
       "       [-3.03734452e-01,  2.46596605e-01, -3.45983058e-01],\n",
       "       [ 2.13379368e-01, -2.45244920e-01, -1.29642665e-01],\n",
       "       [ 3.17237556e-01, -4.37182993e-01,  5.59287369e-02],\n",
       "       [-1.71402544e-01,  9.61837694e-02, -3.26234549e-01],\n",
       "       [-2.66598433e-01,  1.88168809e-01, -3.68507743e-01],\n",
       "       [-8.03919658e-02, -1.54147828e-02, -2.69844294e-01],\n",
       "       [ 3.21001083e-01, -4.21301991e-01,  8.28997791e-02],\n",
       "       [ 1.16825655e-01, -1.91729739e-01, -1.07183076e-01],\n",
       "       [ 3.01259607e-01, -5.89052737e-01, -1.27309307e-01],\n",
       "       [-4.03500527e-01,  3.52789700e-01, -4.25835997e-01],\n",
       "       [ 6.12230152e-02, -7.86061585e-02, -2.60273784e-01]], dtype=float32), label_ids=array([0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0,\n",
       "       1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0,\n",
       "       2, 0, 0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 1, 0, 2, 2, 2, 1, 1, 2, 1, 2, 0],\n",
       "      dtype=int64), metrics={'test_loss': 1.0607444047927856, 'test_accuracy': 0.5, 'test_precision': 0.5, 'test_recall': 0.5, 'test_f1': 0.5, 'test_runtime': 46.8618, 'test_samples_per_second': 1.878, 'test_steps_per_second': 0.128})"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "trainer_bert.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "dbd8f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "output_bert=trainer_bert.predict(test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ecfd7094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 35,  0],\n",
       "       [ 0,  0, 24]], dtype=int64)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix_b=confusion_matrix(y_test,output_bert)\n",
    "matrix_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "36e739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Model/brt_model\n",
      "Configuration saved in ./Model/brt_model\\config.json\n",
      "Model weights saved in ./Model/brt_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save the Bert model\n",
    "trainer_bert.save_model(\"./Model/brt_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233fa364",
   "metadata": {},
   "source": [
    "## Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a2d092a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/vocab.txt from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\ece45ade3e01224cf31fed8e183b306d17b84e8abd415363474cfe72274f7814.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/tokenizer_config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\8b3aea9f7242b3d19268df5b1bfed8f66e08671a72ac0809ada08e5ef1adc592.19eda9a6da5fb0e52a45200c95876729561dde16a69b9116953af6edca1d1e92\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/tokenizer.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\92992b36de47dee64b1d5a31c05d8d51e3075b918a218f5ba4f6e306c4b81b8c.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/google/electra-small-discriminator/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\ca13c16218c6780ec76753d3afa19fcb7cc759e3f63ee87e441562d374762b3d.3dd1921e571dfa18c0bdaa17b9b38f111097812281989b1cb22263738e66ef73\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/electra-small-discriminator/resolve/main/config.json from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\ca13c16218c6780ec76753d3afa19fcb7cc759e3f63ee87e441562d374762b3d.3dd1921e571dfa18c0bdaa17b9b38f111097812281989b1cb22263738e66ef73\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/electra-small-discriminator/resolve/main/pytorch_model.bin from cache at C:\\Users\\M1075352/.cache\\huggingface\\transformers\\1ebdea26ed1a6268cdf5d1fe36450e89c70e306c97d39e62ede8a31f1c43f9ad.baa63624f08a59503441bce3d427225c61fe79bfa9f6d4c30cde7d072d863e0c\n",
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "tokenize_e = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "model_e = ElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator',num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "dcd0f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tokenizer for training and test dataset (Roberta)\n",
    "\n",
    "train_encodings_e = tokenize_e(X_train, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_encodings_e = tokenize_e(X_test, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d31eac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let’s turn our labels and encodings into a Dataset object for Training and test purpose \n",
    "\n",
    "train_e = Dataset(train_encodings_e, y_train)\n",
    "test_e = Dataset(test_encodings_e, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b13086c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "##set the training arguments for traning \n",
    "\n",
    "training_args_e = TrainingArguments(\n",
    "    output_dir='./results_xl',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=2,             \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=16,  \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "fb84a17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 350\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 05:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.101200</td>\n",
       "      <td>1.099062</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.397727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.101100</td>\n",
       "      <td>1.098758</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.101500</td>\n",
       "      <td>1.098164</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.101900</td>\n",
       "      <td>1.097453</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.098400</td>\n",
       "      <td>1.096984</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.100500</td>\n",
       "      <td>1.096779</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.095457</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.095300</td>\n",
       "      <td>1.093957</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-10\n",
      "Configuration saved in ./results_xl\\checkpoint-10\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-10\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-20\n",
      "Configuration saved in ./results_xl\\checkpoint-20\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-20\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-30\n",
      "Configuration saved in ./results_xl\\checkpoint-30\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-30\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-40\n",
      "Configuration saved in ./results_xl\\checkpoint-40\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-40\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-50\n",
      "Configuration saved in ./results_xl\\checkpoint-50\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-60\n",
      "Configuration saved in ./results_xl\\checkpoint-60\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-60\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-70\n",
      "Configuration saved in ./results_xl\\checkpoint-70\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-70\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results_xl\\checkpoint-80\n",
      "Configuration saved in ./results_xl\\checkpoint-80\\config.json\n",
      "Model weights saved in ./results_xl\\checkpoint-80\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results_xl\\checkpoint-80 (score: 1.0939569473266602).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=88, training_loss=1.099972594868053, metrics={'train_runtime': 350.5467, 'train_samples_per_second': 1.997, 'train_steps_per_second': 0.251, 'total_flos': 5751923977800.0, 'train_loss': 1.099972594868053, 'epoch': 2.0})"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "\n",
    "trainer_e = Trainer(\n",
    "    model=model_e,                         \n",
    "    args=training_args_e,                 \n",
    "    train_dataset=train_e,       \n",
    "    eval_dataset=test_e,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_e.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d0ee598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0939569473266602,\n",
       " 'eval_accuracy': 0.375,\n",
       " 'eval_precision': 0.375,\n",
       " 'eval_recall': 0.375,\n",
       " 'eval_f1': 0.375,\n",
       " 'eval_runtime': 7.6394,\n",
       " 'eval_samples_per_second': 11.519,\n",
       " 'eval_steps_per_second': 0.785,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_e.evaluate(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "8b8f79d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.26581416e-02,  2.56708469e-02, -3.23141403e-02],\n",
       "       [-9.04164091e-03,  3.95529754e-02, -3.19599248e-02],\n",
       "       [-7.71410996e-03,  2.53989678e-02, -3.35994251e-02],\n",
       "       [-6.32114755e-03,  1.51349623e-02, -3.02102137e-02],\n",
       "       [ 1.75758975e-03,  2.72639338e-02, -2.92281117e-02],\n",
       "       [-1.42899025e-02,  2.60364991e-02, -1.25040580e-02],\n",
       "       [ 5.15604159e-03,  5.08345589e-02, -3.30824964e-02],\n",
       "       [-9.69893206e-03, -1.43349019e-03, -3.09992116e-02],\n",
       "       [-1.50604658e-02,  4.00619134e-02, -3.22726704e-02],\n",
       "       [-7.73453759e-03,  3.46706547e-02, -5.07052168e-02],\n",
       "       [ 2.32318621e-02,  5.34542203e-02, -2.69919764e-02],\n",
       "       [ 9.38201323e-03,  3.99141870e-02, -2.45080870e-02],\n",
       "       [-1.73859708e-02,  3.30859758e-02, -4.66257706e-02],\n",
       "       [ 4.42313170e-03,  3.80263031e-02, -3.91462892e-02],\n",
       "       [-1.00604966e-02,  2.92416066e-02, -3.96937206e-02],\n",
       "       [-1.04745124e-02,  1.12487273e-02, -4.75973375e-02],\n",
       "       [-2.37181131e-02,  1.74886212e-02, -2.87983678e-02],\n",
       "       [-4.23348369e-03,  2.11372189e-02, -4.52185869e-02],\n",
       "       [ 2.49516908e-02,  4.28285263e-02, -3.08120307e-02],\n",
       "       [-1.17870755e-02,  3.49608101e-02, -3.86047810e-02],\n",
       "       [-8.52747262e-03,  2.90793143e-02, -3.67214158e-02],\n",
       "       [ 1.78529061e-02,  3.12388074e-02, -1.60853453e-02],\n",
       "       [ 2.14180853e-02, -9.81252734e-03, -1.93020515e-02],\n",
       "       [ 7.71171553e-03,  2.81818900e-02, -2.54672505e-02],\n",
       "       [ 6.00384688e-03,  2.37100944e-02, -2.60650348e-02],\n",
       "       [ 3.40151526e-02,  3.95677425e-02, -4.12506312e-02],\n",
       "       [ 1.60632301e-02,  2.93019582e-02, -2.97322776e-02],\n",
       "       [-6.01778971e-03,  1.65152457e-02, -3.84134054e-02],\n",
       "       [ 6.85712462e-03,  4.06007990e-02, -3.12898457e-02],\n",
       "       [ 2.86668222e-02,  1.20092528e-02, -2.93101389e-02],\n",
       "       [ 1.78622045e-02,  3.95728834e-02, -2.41085868e-02],\n",
       "       [-3.62129658e-02,  3.15391682e-02, -3.06668896e-02],\n",
       "       [-1.20177772e-02,  2.31813435e-02, -2.73459349e-02],\n",
       "       [ 2.07550614e-03,  1.67972744e-02, -1.06700463e-02],\n",
       "       [-1.78099459e-03,  4.92212512e-02, -3.41111310e-02],\n",
       "       [ 8.02977569e-03,  1.89728253e-02, -2.78646890e-02],\n",
       "       [-2.24284753e-02,  3.37355025e-02, -3.02058123e-02],\n",
       "       [-2.51507480e-02,  2.54452433e-02, -3.39262448e-02],\n",
       "       [ 1.16762687e-02,  2.66888794e-02, -1.48602016e-02],\n",
       "       [ 1.37625672e-02,  3.90421301e-02, -2.99370196e-02],\n",
       "       [-5.89582557e-03,  2.36134268e-02, -3.55917625e-02],\n",
       "       [-6.42286905e-04,  1.83047839e-02, -6.13899790e-02],\n",
       "       [ 1.35912711e-03,  2.70361472e-02, -2.41477620e-02],\n",
       "       [-2.94263773e-05,  1.78977977e-02, -3.23420390e-02],\n",
       "       [-1.71873383e-02,  1.86453946e-02, -3.32322717e-02],\n",
       "       [-2.73832888e-03,  3.77015658e-02, -4.47461233e-02],\n",
       "       [-7.94688053e-03,  5.39781302e-02, -4.44883704e-02],\n",
       "       [-1.18601788e-02,  2.76724026e-02, -2.85257623e-02],\n",
       "       [ 3.02763446e-03,  2.76329531e-03, -2.20294613e-02],\n",
       "       [ 3.38846422e-03,  3.43686976e-02, -3.30217741e-02],\n",
       "       [-1.59035400e-02,  2.86975969e-02, -3.49928029e-02],\n",
       "       [-4.18520853e-04,  1.74023602e-02, -3.30694541e-02],\n",
       "       [-1.36614151e-04,  4.78547961e-02, -3.41373980e-02],\n",
       "       [ 2.36239843e-02,  3.86827290e-02, -2.94801798e-02],\n",
       "       [-3.28198820e-02,  2.39437558e-02, -3.02964523e-02],\n",
       "       [-1.58688091e-02,  3.22597325e-02, -4.14661802e-02],\n",
       "       [-1.85788032e-02,  3.81695665e-02, -2.76599061e-02],\n",
       "       [-1.43281082e-02,  2.56446265e-02, -3.27156484e-02],\n",
       "       [-7.22556654e-03,  7.08896900e-03, -1.03701381e-02],\n",
       "       [-2.88859964e-03,  1.58892274e-02, -2.85123195e-02],\n",
       "       [-6.44386420e-03,  4.35582176e-02, -2.63697933e-02],\n",
       "       [-7.21145282e-03,  2.97470205e-02, -2.18579993e-02],\n",
       "       [ 1.81810337e-03,  3.86255234e-02, -5.09847701e-02],\n",
       "       [-9.82133858e-03,  1.61886886e-02, -3.77199352e-02],\n",
       "       [-1.41557248e-03,  2.63657290e-02, -1.69507917e-02],\n",
       "       [-3.58477444e-03,  2.91996915e-02, -4.03786674e-02],\n",
       "       [-1.67145338e-02,  2.22891122e-02, -2.47235354e-02],\n",
       "       [-3.93430563e-03,  1.14166383e-02, -2.53316797e-02],\n",
       "       [-1.65950339e-02,  3.99448797e-02, -4.06408235e-02],\n",
       "       [-7.04532163e-03,  2.77077165e-02, -4.15972471e-02],\n",
       "       [ 1.54353380e-02,  2.81377416e-02, -2.67601758e-02],\n",
       "       [ 6.24792604e-03,  2.64462698e-02, -4.76211011e-02],\n",
       "       [-9.85028036e-03,  3.40421610e-02, -4.43305448e-02],\n",
       "       [-3.49887297e-03,  3.13147716e-02, -2.75268946e-02],\n",
       "       [ 1.29004903e-02,  2.57038698e-02, -3.95963192e-02],\n",
       "       [ 1.08194035e-02,  1.97415184e-02, -3.71650942e-02],\n",
       "       [ 1.35751406e-03,  4.87534367e-02, -3.97347324e-02],\n",
       "       [-2.29881168e-03,  4.49384563e-02, -3.94961312e-02],\n",
       "       [ 1.61880273e-02, -8.57351441e-03, -2.96545774e-02],\n",
       "       [-7.63738819e-04,  3.56392823e-02, -2.84212250e-02],\n",
       "       [-1.43162198e-02,  1.73099861e-02, -2.23211665e-02],\n",
       "       [ 3.12052686e-02,  1.48832146e-02, -4.16482985e-02],\n",
       "       [ 1.56448763e-02,  1.39244422e-02, -4.82034460e-02],\n",
       "       [ 2.34754831e-02,  3.68258208e-02, -3.48239280e-02],\n",
       "       [-6.75068283e-03,  3.60051580e-02, -4.26223055e-02],\n",
       "       [ 7.22961174e-03, -3.26367281e-02, -3.42094153e-02],\n",
       "       [ 3.05440761e-02,  1.74179934e-02, -2.30946112e-02],\n",
       "       [ 3.54265474e-04,  2.16336455e-02, -3.97772081e-02]], dtype=float32), label_ids=array([0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0,\n",
       "       1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0,\n",
       "       2, 0, 0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 1, 0, 2, 2, 2, 1, 1, 2, 1, 2, 0],\n",
       "      dtype=int64), metrics={'test_loss': 1.0939569473266602, 'test_accuracy': 0.375, 'test_precision': 0.375, 'test_recall': 0.375, 'test_f1': 0.375, 'test_runtime': 5.9866, 'test_samples_per_second': 14.7, 'test_steps_per_second': 1.002})"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "trainer_e.predict(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "bb4904d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 88\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "output_e=trainer_e.predict(test_e)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d2487ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 35,  0],\n",
       "       [ 0,  0, 24]], dtype=int64)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix_e=confusion_matrix(y_test,output_bert)\n",
    "matrix_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "bdb5283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Model/Electra_model\n",
      "Configuration saved in ./Model/Electra_model\\config.json\n",
      "Model weights saved in ./Model/Electra_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save the DistilBert model\n",
    "trainer_e.save_model(\"./Model/Electra_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf82376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
